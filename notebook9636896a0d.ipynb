{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":89235,"databundleVersionId":10264525,"sourceType":"competition"}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"GPU 스펙 확인","metadata":{}},{"cell_type":"code","source":"!nvidia-smi","metadata":{"execution":{"iopub.status.busy":"2024-12-09T12:39:22.084206Z","iopub.execute_input":"2024-12-09T12:39:22.084966Z","iopub.status.idle":"2024-12-09T12:39:23.254743Z","shell.execute_reply.started":"2024-12-09T12:39:22.084930Z","shell.execute_reply":"2024-12-09T12:39:23.253659Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Mon Dec  9 12:39:23 2024       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n| N/A   76C    P0             30W /   70W |   12783MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n|   1  Tesla T4                       Off |   00000000:00:05.0 Off |                    0 |\n| N/A   70C    P0             29W /   70W |   14565MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n+-----------------------------------------------------------------------------------------+\n","output_type":"stream"}],"execution_count":171},{"cell_type":"code","source":"import subprocess\nfrom ast import literal_eval\n\ndef run(command):\n    process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE)\n    out, err = process.communicate()\n    print(out.decode('utf-8').strip())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T12:39:23.257340Z","iopub.execute_input":"2024-12-09T12:39:23.257788Z","iopub.status.idle":"2024-12-09T12:39:23.263455Z","shell.execute_reply.started":"2024-12-09T12:39:23.257743Z","shell.execute_reply":"2024-12-09T12:39:23.262446Z"}},"outputs":[],"execution_count":172},{"cell_type":"code","source":"import platform\nimport subprocess\n\nprint('# CPU')\nrun('cat /proc/cpuinfo | egrep -m 1 \"^model name\"')\nrun('cat /proc/cpuinfo | egrep -m 1 \"^cpu MHz\"')\nrun('cat /proc/cpuinfo | egrep -m 1 \"^cpu cores\"')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T12:39:23.264705Z","iopub.execute_input":"2024-12-09T12:39:23.265013Z","iopub.status.idle":"2024-12-09T12:39:23.306670Z","shell.execute_reply.started":"2024-12-09T12:39:23.264985Z","shell.execute_reply":"2024-12-09T12:39:23.305726Z"}},"outputs":[{"name":"stdout","text":"# CPU\nmodel name\t: Intel(R) Xeon(R) CPU @ 2.00GHz\ncpu MHz\t\t: 2000.156\ncpu cores\t: 2\n","output_type":"stream"}],"execution_count":173},{"cell_type":"markdown","source":"캐글 데이터 경로 확인","metadata":{"id":"xJ_5vemHnXlZ"}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"id":"g-1-veNcnW6U","outputId":"1aeb2940-0bdd-448c-ed96-0baf7b8d0064","execution":{"iopub.status.busy":"2024-12-09T12:39:23.308489Z","iopub.execute_input":"2024-12-09T12:39:23.308781Z","iopub.status.idle":"2024-12-09T12:39:23.313888Z","shell.execute_reply.started":"2024-12-09T12:39:23.308753Z","shell.execute_reply":"2024-12-09T12:39:23.312939Z"},"trusted":true},"outputs":[],"execution_count":174},{"cell_type":"markdown","source":"### 폴더 경로 설정","metadata":{"id":"G1NrfEiTnlLS"}},{"cell_type":"code","source":"workspace_path = '/kaggle/input/2024-fall-cloud-segmentation'  # 본인의 파일 경로 반영","metadata":{"id":"9oW1RJXWnkxw","execution":{"iopub.status.busy":"2024-12-09T12:39:23.314868Z","iopub.execute_input":"2024-12-09T12:39:23.315124Z","iopub.status.idle":"2024-12-09T12:39:23.329148Z","shell.execute_reply.started":"2024-12-09T12:39:23.315098Z","shell.execute_reply":"2024-12-09T12:39:23.328254Z"},"trusted":true},"outputs":[],"execution_count":175},{"cell_type":"markdown","source":"### 필요한 패키지 로드","metadata":{"id":"86ea40c7"}},{"cell_type":"code","source":"!pip install albumentations==0.4.6\n!pip install yacs","metadata":{"id":"lRfwuEL2--n-","outputId":"f58dedc2-f681-43bc-9d8d-3e01a7d9195e","execution":{"iopub.status.busy":"2024-12-09T12:39:23.330250Z","iopub.execute_input":"2024-12-09T12:39:23.330600Z","iopub.status.idle":"2024-12-09T12:39:39.985288Z","shell.execute_reply.started":"2024-12-09T12:39:23.330573Z","shell.execute_reply":"2024-12-09T12:39:39.984355Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Requirement already satisfied: albumentations==0.4.6 in /opt/conda/lib/python3.10/site-packages (0.4.6)\nRequirement already satisfied: numpy>=1.11.1 in /opt/conda/lib/python3.10/site-packages (from albumentations==0.4.6) (1.26.4)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from albumentations==0.4.6) (1.14.1)\nRequirement already satisfied: imgaug>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from albumentations==0.4.6) (0.4.0)\nRequirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from albumentations==0.4.6) (6.0.2)\nRequirement already satisfied: opencv-python>=4.1.1 in /opt/conda/lib/python3.10/site-packages (from albumentations==0.4.6) (4.10.0.84)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from imgaug>=0.4.0->albumentations==0.4.6) (1.16.0)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from imgaug>=0.4.0->albumentations==0.4.6) (10.3.0)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from imgaug>=0.4.0->albumentations==0.4.6) (3.7.5)\nRequirement already satisfied: scikit-image>=0.14.2 in /opt/conda/lib/python3.10/site-packages (from imgaug>=0.4.0->albumentations==0.4.6) (0.23.2)\nRequirement already satisfied: imageio in /opt/conda/lib/python3.10/site-packages (from imgaug>=0.4.0->albumentations==0.4.6) (2.34.1)\nRequirement already satisfied: Shapely in /opt/conda/lib/python3.10/site-packages (from imgaug>=0.4.0->albumentations==0.4.6) (1.8.5.post1)\nRequirement already satisfied: networkx>=2.8 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (3.3)\nRequirement already satisfied: tifffile>=2022.8.12 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (2024.5.22)\nRequirement already satisfied: packaging>=21 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (21.3)\nRequirement already satisfied: lazy-loader>=0.4 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (0.4)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (1.2.1)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (4.53.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (1.4.5)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (3.1.2)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (2.9.0.post0)\nRequirement already satisfied: yacs in /opt/conda/lib/python3.10/site-packages (0.1.8)\nRequirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from yacs) (6.0.2)\n","output_type":"stream"}],"execution_count":176},{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn.functional as F\nimport yaml\nimport numpy as np\nimport cv2\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nimport random\nimport torch.backends.cudnn as cudnn\nimport time\nfrom torchvision import models\nfrom tqdm import tqdm","metadata":{"id":"52bbfdfb","execution":{"iopub.status.busy":"2024-12-09T12:39:39.986706Z","iopub.execute_input":"2024-12-09T12:39:39.987013Z","iopub.status.idle":"2024-12-09T12:39:39.992415Z","shell.execute_reply.started":"2024-12-09T12:39:39.986981Z","shell.execute_reply":"2024-12-09T12:39:39.991557Z"},"trusted":true},"outputs":[],"execution_count":177},{"cell_type":"markdown","source":"### 재구현 세팅","metadata":{"id":"649609b1"}},{"cell_type":"code","source":"def init_seeds(seed):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    cudnn.deterministic = True\n    cudnn.benchmark = False","metadata":{"id":"c35eec19","execution":{"iopub.status.busy":"2024-12-09T12:39:39.993288Z","iopub.execute_input":"2024-12-09T12:39:39.993594Z","iopub.status.idle":"2024-12-09T12:39:40.005165Z","shell.execute_reply.started":"2024-12-09T12:39:39.993568Z","shell.execute_reply":"2024-12-09T12:39:40.004374Z"},"trusted":true},"outputs":[],"execution_count":178},{"cell_type":"code","source":"init_seeds(0)","metadata":{"id":"b90c4ec5","execution":{"iopub.status.busy":"2024-12-09T12:39:40.006282Z","iopub.execute_input":"2024-12-09T12:39:40.007005Z","iopub.status.idle":"2024-12-09T12:39:40.015216Z","shell.execute_reply.started":"2024-12-09T12:39:40.006967Z","shell.execute_reply":"2024-12-09T12:39:40.014547Z"},"trusted":true},"outputs":[],"execution_count":179},{"cell_type":"markdown","source":"### 데이터 로드","metadata":{"id":"3f8a343a"}},{"cell_type":"code","source":"rgb_path = os.path.join(workspace_path, 'train/rgb/')\nngr_path = os.path.join(workspace_path, 'train/ngr/')\nlabel_path = os.path.join(workspace_path, 'train/label/')","metadata":{"id":"499b3f23","execution":{"iopub.status.busy":"2024-12-09T12:39:40.017923Z","iopub.execute_input":"2024-12-09T12:39:40.018255Z","iopub.status.idle":"2024-12-09T12:39:40.027032Z","shell.execute_reply.started":"2024-12-09T12:39:40.018227Z","shell.execute_reply":"2024-12-09T12:39:40.026261Z"},"trusted":true},"outputs":[],"execution_count":180},{"cell_type":"code","source":"rgb_images = os.listdir(rgb_path)\nrgb_images = [os.path.join(rgb_path,x) for x in rgb_images]\nngr_images = os.listdir(ngr_path)\nngr_images = [os.path.join(ngr_path, x) for x in ngr_images]\nlabel_images = os.listdir(label_path)\nlabel_images = [os.path.join(label_path, x) for x in label_images]","metadata":{"id":"d4e26b49","execution":{"iopub.status.busy":"2024-12-09T12:39:40.027938Z","iopub.execute_input":"2024-12-09T12:39:40.028179Z","iopub.status.idle":"2024-12-09T12:39:40.045049Z","shell.execute_reply.started":"2024-12-09T12:39:40.028155Z","shell.execute_reply":"2024-12-09T12:39:40.044350Z"},"trusted":true},"outputs":[],"execution_count":181},{"cell_type":"markdown","source":"### 데이터셋 클래스 정의","metadata":{"id":"997d5237"}},{"cell_type":"code","source":"class CloudDataset(torch.utils.data.Dataset):\n    def __init__(self, image_path, label_path, patch_size = 400, patch_stride = 100, is_train = True, cache_dir = './cache', transforms = None):\n        self.image_path = image_path\n        self.label_path = label_path\n        self.patch_size = patch_size\n        self.patch_stride = patch_stride\n        self.is_train = is_train\n        self.transforms = transforms\n        \n        self.patch_images = []\n        self.patch_labels = []\n        \n        \n        cache_dir = cache_dir\n        os.makedirs(cache_dir, exist_ok=True)\n        if is_train:\n            for img_path in self.image_path:\n                img = cv2.imread(img_path)\n                img_count = 0\n                for x in range(0, img.shape[0]-self.patch_size+1, self.patch_stride):\n                    for y in range(0, img.shape[1]-self.patch_size+1, self.patch_stride):\n                        patch_image = img[x:x+patch_size, y:y+patch_size, :].copy()\n                        patch_path = f'rgb_{os.path.splitext(os.path.basename(img_path))[0]}_{img_count}.png'\n                        if not os.path.isfile(os.path.join(cache_dir, patch_path)):\n                            cv2.imwrite(os.path.join(cache_dir, patch_path), patch_image)\n                        self.patch_images.append(os.path.join(cache_dir, patch_path))\n                        img_count += 1\n\n            for label_path in self.label_path:\n                img = cv2.imread(label_path)\n                img_count = 0\n                for x in range(0, img.shape[0]-self.patch_size+1, self.patch_stride):\n                    for y in range(0, img.shape[1]-self.patch_size+1, self.patch_stride):\n                        patch_image = img[x:x+patch_size, y:y+patch_size, :].copy()\n                        patch_path = f'label_{os.path.splitext(os.path.basename(label_path))[0]}_{img_count}.png'\n                        if not os.path.isfile(os.path.join(cache_dir, patch_path)):\n                            cv2.imwrite(os.path.join(cache_dir, patch_path), patch_image)\n                        self.patch_labels.append(os.path.join(cache_dir, patch_path))\n                        img_count += 1\n        else:\n            self.patch_images = self.image_path\n            self.patch_labels = self.label_path\n    def __len__(self):\n        return len(self.patch_images)\n        \n    def __getitem__(self, idx):\n        img = cv2.imread(self.patch_images[idx])\n        \n        if self.is_train:\n            label = cv2.imread(self.patch_labels[idx])\n            # numpy arrays to tensors\n            h, w = label.shape[:2]\n        \n            target = np.zeros((h, w), dtype=np.uint8)\n            pos = np.where(np.all(label == [0, 0, 255], axis=-1))  # thick cloud\n            target[pos] = 1\n            pos = np.where(np.all(label == [0, 255, 0], axis=-1))  # thin cloud\n            target[pos] = 2\n            pos = np.where(np.all(label == [0, 255, 255], axis=-1))  # cloud shadow\n            target[pos] = 3\n        else:\n            target = img\n        if self.transforms is not None:\n            img, target = self.transforms(img, target)\n            \n        if self.is_train:\n            return img, target\n        else:\n            return img, self.patch_images[idx]","metadata":{"id":"ca96420c","execution":{"iopub.status.busy":"2024-12-09T12:39:40.046403Z","iopub.execute_input":"2024-12-09T12:39:40.046663Z","iopub.status.idle":"2024-12-09T12:39:40.060738Z","shell.execute_reply.started":"2024-12-09T12:39:40.046638Z","shell.execute_reply":"2024-12-09T12:39:40.059937Z"},"trusted":true},"outputs":[],"execution_count":182},{"cell_type":"markdown","source":"### 파라미터 세팅","metadata":{"id":"09d79e8b"}},{"cell_type":"code","source":"batch_size = 32\nepochs = 4\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\npatch_size = 512\npatch_stride = 256\nnum_workers = 4\nprefetch_factor = 2 # 메모리 부하 고려?\n\nnum_classes = 4\nclass_names = ['thick cloud', 'thin cloud', 'cloud shadow']\n\ntrain_data_rate = 0.7\n\nmodel_name = 'dilated_unet'\n\nloss_func = 'dice'","metadata":{"id":"a6ac4eae","execution":{"iopub.status.busy":"2024-12-09T12:39:40.061780Z","iopub.execute_input":"2024-12-09T12:39:40.062526Z","iopub.status.idle":"2024-12-09T12:39:40.075432Z","shell.execute_reply.started":"2024-12-09T12:39:40.062488Z","shell.execute_reply":"2024-12-09T12:39:40.074797Z"},"trusted":true},"outputs":[],"execution_count":183},{"cell_type":"markdown","source":"### 데이터증대","metadata":{"id":"7e4513b1"}},{"cell_type":"code","source":"class ImageAug:\n    def __init__(self):\n        # self.aug = A.Compose([A.HorizontalFlip(p=0.5),\n        #                      A.VerticalFlip(p=0.5),\n        #                      A.ShiftScaleRotate(p=0.5),\n        #                      A.RandomBrightnessContrast(p=0.3),\n        #                      A.Normalize(),\n        #                      ToTensorV2()])\n        self.aug = A.Compose([\n            A.RandomRotate90(p=0.5),\n            A.Flip(p=0.5),\n            A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.1, rotate_limit=45, p=0.5),\n            A.OneOf([\n                A.ElasticTransform(alpha=120, sigma=120 * 0.05, alpha_affine=120 * 0.03, p=0.5),\n                A.GridDistortion(p=0.5),\n                A.OpticalDistortion(distort_limit=1, shift_limit=0.5, p=0.5),\n            ], p=0.3),\n            A.CLAHE(p=0.5),\n            A.RandomBrightnessContrast(p=0.5),\n            A.Normalize(),\n            ToTensorV2()\n        ])\n        \n    def __call__(self, img, label):\n        transformed = self.aug(image=img, mask=label)\n        return transformed['image'], transformed['mask']\n\nclass DefaultAug:\n    def __init__(self):\n        self.aug = A.Compose([A.Normalize(),\n                             ToTensorV2()])\n\n    def __call__(self, img, label):\n        transformed = self.aug(image=img, mask=label)\n        return transformed['image'], transformed['mask']","metadata":{"id":"17dc2c12","execution":{"iopub.status.busy":"2024-12-09T12:39:40.076471Z","iopub.execute_input":"2024-12-09T12:39:40.076758Z","iopub.status.idle":"2024-12-09T12:39:40.086311Z","shell.execute_reply.started":"2024-12-09T12:39:40.076719Z","shell.execute_reply":"2024-12-09T12:39:40.085689Z"},"trusted":true},"outputs":[],"execution_count":184},{"cell_type":"code","source":"train_transforms = ImageAug()\nval_transforms = DefaultAug()","metadata":{"id":"03a59423","execution":{"iopub.status.busy":"2024-12-09T12:39:40.087312Z","iopub.execute_input":"2024-12-09T12:39:40.087606Z","iopub.status.idle":"2024-12-09T12:39:40.101123Z","shell.execute_reply.started":"2024-12-09T12:39:40.087581Z","shell.execute_reply":"2024-12-09T12:39:40.100413Z"},"trusted":true},"outputs":[],"execution_count":185},{"cell_type":"markdown","source":"### 데이터셋 정의","metadata":{"id":"2147f462"}},{"cell_type":"code","source":"output_path = '/kaggle/working'\n#train dataset\ntrain_dataset = CloudDataset(rgb_images[:int(len(rgb_images)*train_data_rate)], label_images[:int(len(label_images)*train_data_rate)],\n                            transforms=train_transforms, cache_dir=os.path.join(output_path, 'cache'))\ntrain_dataloader = torch.utils.data.DataLoader(\n    train_dataset, \n    batch_size=batch_size, \n    shuffle=True,\n    num_workers=num_workers,\n    prefetch_factor=prefetch_factor,\n    pin_memory=True, \n    drop_last=True,\n    persistent_workers=True)\n\n#valid dataset\nval_dataset = CloudDataset(rgb_images[int(len(rgb_images)*train_data_rate):], label_images[int(len(label_images)*train_data_rate):],\n                            transforms=val_transforms, cache_dir=os.path.join(output_path, 'cache'))\nval_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=True,\n                                               num_workers=num_workers, pin_memory=True, drop_last=True)","metadata":{"id":"98bed485","execution":{"iopub.status.busy":"2024-12-09T12:39:40.102056Z","iopub.execute_input":"2024-12-09T12:39:40.102343Z","iopub.status.idle":"2024-12-09T12:47:14.390473Z","shell.execute_reply.started":"2024-12-09T12:39:40.102307Z","shell.execute_reply":"2024-12-09T12:47:14.389722Z"},"trusted":true},"outputs":[],"execution_count":186},{"cell_type":"markdown","source":"### 모델 정의","metadata":{"id":"55cbab53"}},{"cell_type":"code","source":"def count_parameters(model):\n    return sum(p.numel() for p in model.parameters() if p.requires_grad)","metadata":{"id":"e54a2c7d","trusted":true,"execution":{"iopub.status.busy":"2024-12-09T12:47:14.391513Z","iopub.execute_input":"2024-12-09T12:47:14.391776Z","iopub.status.idle":"2024-12-09T12:47:14.396100Z","shell.execute_reply.started":"2024-12-09T12:47:14.391748Z","shell.execute_reply":"2024-12-09T12:47:14.395255Z"}},"outputs":[],"execution_count":187},{"cell_type":"code","source":"import torch.nn as nn\n\nclass DoubleConvBlock(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super(DoubleConvBlock, self).__init__()\n        self.block = nn.Sequential(nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n                                   nn.ReLU(inplace=True),\n                                   nn.BatchNorm2d(out_channels),\n                                   nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n                                   nn.ReLU(inplace=True),\n                                   nn.BatchNorm2d(out_channels))\n\n    def forward(self, x):\n        x = self.block(x)\n        return x\n\n\nclass DilatedConvBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, dilation, padding):\n        super(DilatedConvBlock, self).__init__()\n        self.block = nn.Sequential(nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=padding, dilation=dilation),\n                                   nn.ReLU(inplace=True),\n                                   nn.BatchNorm2d(out_channels))\n\n    def forward(self, x):\n        x = self.block(x)\n        return x\n\n\n\n\nclass ConcatDoubleConvBlock(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super(ConcatDoubleConvBlock, self).__init__()\n        self.block = nn.Sequential(nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n                                   nn.ReLU(inplace=True),\n                                   nn.BatchNorm2d(out_channels),\n                                   nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n                                   nn.ReLU(inplace=True),\n                                   nn.BatchNorm2d(out_channels))\n\n    def forward(self, x, skip):\n        x = torch.cat((skip, x), dim=1)\n        x = self.block(x)\n        return x\n\n\n\nclass MyDilatedConvUNet(nn.Module):\n    def __init__(self, filters=44, depth=3, bottleneck_depth=6):\n        super(MyDilatedConvUNet, self).__init__()\n        self.depth = depth\n        self.encoder_path = nn.ModuleList()\n        src_in_channels = 3     # Geo-TIFF has four channels (R, G, B, and NIR)\n        for d in range(depth):\n            in_channels = src_in_channels if d == 0 else filters * 2 ** (d-1)\n            self.encoder_path.append(\n                DoubleConvBlock(in_channels, filters * 2 ** d))\n        self.maxpool = nn.MaxPool2d(2, 2, padding=0)\n        self.bottleneck_path = nn.ModuleList()\n        for d in range(bottleneck_depth):\n            in_channels = filters * 2 ** (depth - 1) if d == 0 else filters * 2 ** depth\n            self.bottleneck_path.append(DilatedConvBlock(in_channels, filters * 2 ** depth, 2 ** d, 2 ** d))\n        self.decoder_path = nn.ModuleList()\n        for d in range(depth):\n            in_channels = filters * 2 ** (depth - d)\n            self.decoder_path.append(ConcatDoubleConvBlock(in_channels, filters * 2 ** (depth - d - 1)))\n        self.up_path = nn.ModuleList()\n        for d in range(depth):\n            in_channels = filters * 2 ** (depth - d)\n            self.up_path.append(nn.ConvTranspose2d(in_channels, filters * 2 ** (depth - d - 1),\n                                                        kernel_size=4, stride=2, padding=1))\n        out_channels = 4     # output channels (num_classes + 1(background))\n        self.last_conv = nn.Conv2d(filters, out_channels, kernel_size=1)\n\n    def forward(self, x):\n        skip = []\n        for block in self.encoder_path:\n            x = block(x)\n            skip.append(x)\n            x = self.maxpool(x)\n        dilated = []\n        for block in self.bottleneck_path:\n            x = block(x)\n            dilated.append(x)\n        x = torch.stack(dilated, dim=-1).sum(dim=-1)  # sum over list\n\n        # up-sampling and double convolutions\n        for d in range(self.depth):\n            x = self.up_path[d](x)\n            x = self.decoder_path[d](x, skip[-(d+1)])\n\n        return self.last_conv(x)","metadata":{"id":"eIK90NknzGPn","trusted":true,"execution":{"iopub.status.busy":"2024-12-09T12:47:14.397291Z","iopub.execute_input":"2024-12-09T12:47:14.397579Z","iopub.status.idle":"2024-12-09T12:47:14.418921Z","shell.execute_reply.started":"2024-12-09T12:47:14.397554Z","shell.execute_reply":"2024-12-09T12:47:14.418020Z"}},"outputs":[],"execution_count":188},{"cell_type":"code","source":"# Model\nif model_name == 'deeplabv3':\n    model = models.segmentation.deeplabv3_resnet101(pretrained=False, progress=True, num_classes=4)\nelif model_name == 'dilated_unet':\n    model = MyDilatedConvUNet()\n\nmodel.to(device)\n\nprint('number of parameters: ', count_parameters(model))","metadata":{"id":"78338b36","outputId":"0c6e4902-ac7e-4e22-b79f-a6af6efaebcf","trusted":true,"execution":{"iopub.status.busy":"2024-12-09T12:47:14.419954Z","iopub.execute_input":"2024-12-09T12:47:14.420233Z","iopub.status.idle":"2024-12-09T12:47:14.511872Z","shell.execute_reply.started":"2024-12-09T12:47:14.420198Z","shell.execute_reply":"2024-12-09T12:47:14.511055Z"}},"outputs":[{"name":"stdout","text":"number of parameters:  9083804\n","output_type":"stream"}],"execution_count":189},{"cell_type":"markdown","source":"### Opimizer 정의","metadata":{"id":"467743f7"}},{"cell_type":"code","source":"from torch.cuda.amp import autocast, GradScaler\nfrom torch.optim.lr_scheduler import OneCycleLR\n\ntorch.backends.cudnn.benchmark = True\nmodel = torch.nn.DataParallel(model) \n\noptimizer = torch.optim.AdamW(model.parameters(),     lr=3e-4,\n    weight_decay=1e-4) \n\n# ３ｅ에서 수정sadsad\n\n# OneCycleLR 설정\nsteps_per_epoch = len(train_dataloader)\nscheduler = OneCycleLR(\n    optimizer,\n    max_lr=1e-3,\n    epochs=epochs,\n    steps_per_epoch=steps_per_epoch,\n    pct_start=0.3,\n    anneal_strategy='cos',\n    div_factor=25.0,\n    final_div_factor=1e4\n)\n\nscaler = GradScaler()","metadata":{"id":"314acf1e","trusted":true,"execution":{"iopub.status.busy":"2024-12-09T12:47:14.512838Z","iopub.execute_input":"2024-12-09T12:47:14.513081Z","iopub.status.idle":"2024-12-09T12:47:14.520395Z","shell.execute_reply.started":"2024-12-09T12:47:14.513057Z","shell.execute_reply":"2024-12-09T12:47:14.519537Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_30/3278708397.py:25: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = GradScaler()\n","output_type":"stream"}],"execution_count":190},{"cell_type":"code","source":"# 옵티마이저 타입 확인\nprint(\"Optimizer type:\", type(optimizer))\n\n# 학습 중 loss 변화 로그 확인\n\n# 저장된 모델 파일 타임스탬프 확인","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T12:47:14.521481Z","iopub.execute_input":"2024-12-09T12:47:14.522270Z","iopub.status.idle":"2024-12-09T12:47:14.528889Z","shell.execute_reply.started":"2024-12-09T12:47:14.522219Z","shell.execute_reply":"2024-12-09T12:47:14.528053Z"}},"outputs":[{"name":"stdout","text":"Optimizer type: <class 'torch.optim.adamw.AdamW'>\n","output_type":"stream"}],"execution_count":191},{"cell_type":"markdown","source":"### 필요 함수 정의","metadata":{"id":"QuJfaks1zbtC"}},{"cell_type":"code","source":"def fitness_test(true, pred, num_classes=4):\n    eps = 1e-7\n    true_one_hot = F.one_hot(true.squeeze(1), num_classes=num_classes)  # (B, 1, H, W) to (B, H, W, C)\n    true_one_hot = true_one_hot.permute(0, 3, 1, 2)  # (B, H, W, C) to (B, C, H, W)\n    pred_max = pred.argmax(1)      # (B, C, H, W) to (B, H, W)\n    pix_acc = (true == pred_max.unsqueeze(1)).sum().float().div(true.nelement())\n    pred_one_hot = F.one_hot(pred_max, num_classes=num_classes)   # (B, H, W) to (B, H, W, C)\n    pred_one_hot = pred_one_hot.permute(0, 3, 1, 2)   # (B, H, W, C) to (B, C, H, W)\n\n    true_one_hot = true_one_hot.type(pred_one_hot.type())\n    dims = (0,) + tuple(range(2, true.ndimension()))  # dims = (0, 2, 3)\n    intersection = torch.sum(pred_one_hot & true_one_hot, dims)\n    union = torch.sum(pred_one_hot | true_one_hot, dims)\n    m_iou = (intersection / (union + eps)).mean()\n\n    return m_iou.item(), pix_acc.item()","metadata":{"id":"c124f5df","trusted":true,"execution":{"iopub.status.busy":"2024-12-09T12:47:14.529917Z","iopub.execute_input":"2024-12-09T12:47:14.530181Z","iopub.status.idle":"2024-12-09T12:47:14.542078Z","shell.execute_reply.started":"2024-12-09T12:47:14.530155Z","shell.execute_reply":"2024-12-09T12:47:14.541049Z"}},"outputs":[],"execution_count":192},{"cell_type":"code","source":"# Loss 함수 정의\ndef ce_loss(true, logits, ignore=255):\n    \"\"\"Computes the weighted multi-class cross-entropy loss.\n    Args:\n        true: a tensor of shape [B, 1, H, W].\n        logits: a tensor of shape [B, C, H, W]. Corresponds to\n            the raw output or logits of the model.\n        ignore: the class index to ignore.\n    Returns:\n        ce_loss: the weighted multi-class cross-entropy loss.\n    \"\"\"\n    ce_loss = F.cross_entropy(\n        logits.float(),\n        true.squeeze(1).long(),    # [B, H, W]\n        ignore_index=ignore,\n    )\n    return ce_loss\n\n\ndef dice_loss(true, logits, eps=1e-7):\n    \"\"\"Computes the Sørensen–Dice loss.\n    Note that PyTorch optimizers minimize a loss. In this\n    case, we would like to maximize the dice loss so we\n    return the negated dice loss.\n    Args:\n        true: a tensor of shape [B, 1, H, W].\n        logits: a tensor of shape [B, C, H, W]. Corresponds to\n            the raw output or logits of the model.\n        eps: added to the denominator for numerical stability.\n    Returns:\n        dice_loss: the Sørensen–Dice loss.\n    \"\"\"\n    num_classes = logits.shape[1]\n    if num_classes == 1:\n        true_1_hot = torch.eye(num_classes + 1)[true.squeeze(1)]\n        true_1_hot = true_1_hot.permute(0, 3, 1, 2).float()\n        true_1_hot_f = true_1_hot[:, 0:1, :, :]\n        true_1_hot_s = true_1_hot[:, 1:2, :, :]\n        true_1_hot = torch.cat([true_1_hot_s, true_1_hot_f], dim=1)\n        pos_prob = torch.sigmoid(logits)\n        neg_prob = 1 - pos_prob\n        probas = torch.cat([pos_prob, neg_prob], dim=1)\n    else:\n        # true_1_hot = torch.eye(num_classes)[true.squeeze(1)]\n        true_1_hot = F.one_hot(true.squeeze(1), num_classes=num_classes)   # (B, 1, H, W) to (B, H, W, C)\n        true_1_hot = true_1_hot.permute(0, 3, 1, 2)                        # (B, H, W, C) to (B, C, H, W)\n        probas = F.softmax(logits, dim=1)\n    true_1_hot = true_1_hot.type(logits.type()).contiguous()\n    dims = (0,) + tuple(range(2, true.ndimension()))        # dims = (0, 2, 3)\n    intersection = torch.sum(probas * true_1_hot, dims)     # intersection w.r.t. the class\n    cardinality = torch.sum(probas + true_1_hot, dims)      # cardinality w.r.t. the class\n    dice_loss = (2. * intersection / (cardinality + eps)).mean()\n    return (1 - dice_loss)\n\n\ndef jaccard_loss(true, logits, eps=1e-7):\n    \"\"\"Computes the Jaccard loss, a.k.a the IoU loss.\n    Note that PyTorch optimizers minimize a loss. In this\n    case, we would like to maximize the jaccard loss so we\n    return the negated jaccard loss.\n    Args:\n        true: a tensor of shape [B, 1, H, W].\n        logits: a tensor of shape [B, C, H, W]. Corresponds to\n            the raw output or logits of the model.\n        eps: added to the denominator for numerical stability.\n    Returns:\n        jacc_loss: the Jaccard loss.\n    \"\"\"\n    num_classes = logits.shape[1]\n    if num_classes == 1:\n        true_1_hot = torch.eye(num_classes + 1)[true.squeeze(1)]\n        true_1_hot = true_1_hot.permute(0, 3, 1, 2).float()\n        true_1_hot_f = true_1_hot[:, 0:1, :, :]\n        true_1_hot_s = true_1_hot[:, 1:2, :, :]\n        true_1_hot = torch.cat([true_1_hot_s, true_1_hot_f], dim=1)\n        pos_prob = torch.sigmoid(logits)\n        neg_prob = 1 - pos_prob\n        probas = torch.cat([pos_prob, neg_prob], dim=1)\n    else:\n        true_1_hot = F.one_hot(true.squeeze(1), num_classes=num_classes)  # (B, 1, H, W) to (B, H, W, C)\n        true_1_hot = true_1_hot.permute(0, 3, 1, 2)  # (B, H, W, C) to (B, C, H, W)\n        probas = F.softmax(logits, dim=1)\n    true_1_hot = true_1_hot.type(logits.type()).contiguous()\n    dims = (0,) + tuple(range(2, true.ndimension()))\n    intersection = torch.sum(probas * true_1_hot, dims)\n    cardinality = torch.sum(probas + true_1_hot, dims)\n    union = cardinality - intersection\n    jacc_loss = (intersection / (union + eps)).mean()\n    return (1 - jacc_loss)","metadata":{"id":"v74FWycdzdev","trusted":true,"execution":{"iopub.status.busy":"2024-12-09T12:47:14.543477Z","iopub.execute_input":"2024-12-09T12:47:14.543799Z","iopub.status.idle":"2024-12-09T12:47:14.557238Z","shell.execute_reply.started":"2024-12-09T12:47:14.543762Z","shell.execute_reply":"2024-12-09T12:47:14.556405Z"}},"outputs":[],"execution_count":193},{"cell_type":"markdown","source":"### 학습 함수 정의","metadata":{"id":"9d1af165"}},{"cell_type":"code","source":"\n\ndef train(model, optimizer, train_dataloader, val_dataloader, loss_func, epochs, device, patch_size=400, save_path='./ckpt'):\n    start_epoch = 0\n    resume = True\n\n    if not os.path.isdir(save_path):\n        os.mkdir(save_path)\n\n    weight_file = save_path + '/{}.pt'.format(model_name)\n\n    best_fit = 0.0\n    num_epochs = epochs\n\n    if resume:\n        if os.path.exists(weight_file):\n            checkpoint = torch.load(weight_file)\n            model.load_state_dict(checkpoint['model'])\n            start_epoch = checkpoint['epoch'] + 1\n            best_fit = checkpoint['best_fit']\n            print(\"Starting training for %g epochs...\" % start_epoch)\n\n    # Start training\n\n    for epoch in range(start_epoch, num_epochs):\n        # loss, metric = train_one_epoch(model, optimizer, dataloader, device, epoch)\n        t0 = time.time()\n        loss = train_one_epoch(model, optimizer, scheduler, train_dataloader, loss_func, device, epoch, num_epochs, scaler)\n        t1 = time.time()\n        print('[Epoch %g] loss=%.4f, time=%.1f' % (epoch, loss.item(), t1 - t0))\n#        if lr_scheduler is not None:\n#           lr_scheduler.step(loss)\n        #tb_writer.add_scalar('learning_rate', optimizer.param_groups[0]['lr'], epoch)\n\n        state = {'model_name': model_name, 'epoch': epoch, 'best_fit': best_fit, 'model': model.state_dict()}\n        torch.save(state, weight_file)\n\n        #tb_writer.add_scalar('train_epoch_loss', loss, epoch)\n\n        # validation\n        patch_size = patch_size\n        fit = val_one_epoch(model, val_dataloader, device, epoch, num_epochs, patch_size)\n        if fit > best_fit:\n            print(\"best fit so far=>saved\")\n            torch.save(state, os.path.join(save_path, '{}_best.pt'.format(model_name)))\n            best_fit = fit\n\n\ndef train_one_epoch(model, optimizer, scheduler, data_loader, loss_func, device, epoch, num_epochs, scaler):\n    model.train()\n    losses = np.array([])\n    metrics = np.array([])\n    bi0 = epoch * len(data_loader)  # batch index\n\n    print(('\\n' + '%10s' * 2) % ('Epoch', 'loss'))\n    pbar = tqdm(enumerate(data_loader), total=len(data_loader))\n    s = ('%10s' + '%10.4f') % (\n        '-/%g' % (num_epochs - 1), 0.0)\n    pbar.set_description(s)\n    for i, (imgs, targets) in pbar:\n        imgs, targets = imgs.to(device), targets.to(device)\n        if model_name == 'deeplabv3':\n            preds = model(imgs)['out']\n            targets = targets.long()\n        elif model_name == 'hrnet_w18' or model_name == 'hrnet_w48':\n            preds = model(imgs)\n            h, w = preds.shape[2], preds.shape[3]\n            targets = F.interpolate(targets.float(), size=(h, w), mode='nearest').long()\n        elif model_name == 'dilated_unet':\n            preds = model(imgs)\n            targets = targets.long()\n            \n        if loss_func == 'jaccard':\n            loss = jaccard_loss(targets, preds)\n        elif loss_func == 'dice':\n            loss = dice_loss(targets, preds)\n        elif loss_func == 'ce':\n            loss = ce_loss(targets, preds)\n        else:\n            print('unsupported loss function')\n            exit(1)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        with torch.no_grad():\n            # cv2_imshow(imgs[0], preds[0])\n            losses = np.append(losses, loss.item())\n\n            s = ('%10s' + '%10.4f') % (\n                '%g/%g' % (epoch, num_epochs - 1), loss.item())\n            pbar.set_description(s)\n            bi = bi0 + i\n            #tb_writer.add_scalar('train_batch_loss', loss.item(), bi)\n\n    epoch_loss = losses.mean()\n\n    return epoch_loss\n\n\ndef val_one_epoch(model, data_loader, device, epoch, num_epochs, patch_size):\n    model.eval()\n    m_iou_list = np.array([])\n    pix_acc_list = np.array([])\n\n    print(('\\n' + '%10s' * 3) % ('Epoch(V)', 'mIOU', 'Accuracy'))\n    pbar = tqdm(enumerate(data_loader), total=len(data_loader))\n    s = ('%10s' + '%10.4f' + ' %8.4f') % (\n        '-/%g' % (num_epochs - 1), 0.0, 0.0)\n    pbar.set_description(s)\n\n    for i, (imgs, targets) in pbar:\n        imgs, targets = imgs.to(device), targets.to(device)\n        with torch.no_grad():  # validation에서는 gradient 계산 불필요\n            if model_name == 'deeplabv3':\n                preds = model(imgs)['out']\n                targets = targets.long()\n            elif model_name == 'hrnet_w18' or model_name == 'hrnet_w48':\n                preds = model(imgs)\n                h, w = preds.shape[2], preds.shape[3]\n                targets = F.interpolate(targets.float(), size=(h, w), mode='nearest').long()\n            elif model_name == 'dilated_unet':\n                preds = model(imgs)\n                targets = targets.long()\n\n            m_iou, pix_acc = fitness_test(targets, preds)\n\n            s = ('%10s' + '%10.4f' + ' %8.4f') % (\n                '%g/%g' % (epoch, num_epochs - 1), m_iou, pix_acc)\n            pbar.set_description(s)\n            m_iou_list = np.append(m_iou_list, m_iou)\n            pix_acc_list = np.append(pix_acc_list, pix_acc)\n\n    val_m_iou_mean = m_iou_list.mean()\n    val_pix_acc_mean = pix_acc_list.mean()\n    print('[V] mIOU={:.3f}, Accuracy={:.3f}'.format(val_m_iou_mean, val_pix_acc_mean))\n    return val_pix_acc_mean","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T12:47:14.558423Z","iopub.execute_input":"2024-12-09T12:47:14.558709Z","iopub.status.idle":"2024-12-09T12:47:14.579773Z","shell.execute_reply.started":"2024-12-09T12:47:14.558683Z","shell.execute_reply":"2024-12-09T12:47:14.578828Z"}},"outputs":[],"execution_count":194},{"cell_type":"markdown","source":"### 학습 시작","metadata":{"id":"600d9790"}},{"cell_type":"code","source":"print(os.listdir(workspace_path))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T12:47:14.580781Z","iopub.execute_input":"2024-12-09T12:47:14.581308Z","iopub.status.idle":"2024-12-09T12:47:14.594792Z","shell.execute_reply.started":"2024-12-09T12:47:14.581280Z","shell.execute_reply":"2024-12-09T12:47:14.594003Z"}},"outputs":[{"name":"stdout","text":"['sample_submission.csv', 'test', 'train']\n","output_type":"stream"}],"execution_count":195},{"cell_type":"code","source":"train(model, optimizer, train_dataloader, val_dataloader, loss_func, epochs, device, patch_size=patch_size, save_path=os.path.join(output_path, 'ckpt'))","metadata":{"id":"b74e3dff","outputId":"b4ce8779-71be-4428-a357-78010400d46a","trusted":true,"execution":{"iopub.status.busy":"2024-12-09T12:47:14.596097Z","iopub.execute_input":"2024-12-09T12:47:14.596449Z"}},"outputs":[{"name":"stdout","text":"Starting training for 1 epochs...\n\n     Epoch      loss\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_30/157406423.py:15: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  checkpoint = torch.load(weight_file)\n       -/3    0.0000:   0%|          | 0/888 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n","output_type":"stream"}],"execution_count":null},{"cell_type":"markdown","source":"### 최고 성능 모델 로드","metadata":{"id":"f8c906b3"}},{"cell_type":"code","source":"save_path=os.path.join(output_path, 'ckpt')\n\ncheckpoint_path = os.path.join(save_path,'{}_best.pt'.format(model_name))\ncheckpoint = torch.load(checkpoint_path)\n\nmodel.load_state_dict(checkpoint['model'])\nmodel.to(device)\n\nprint('model load success')","metadata":{"id":"1f298c14","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 테스트 데이터셋 정의","metadata":{"id":"74453fb5"}},{"cell_type":"code","source":"test_rgb_path = os.path.join(workspace_path, 'test/rgb')\ntest_rgb_images = os.listdir(test_rgb_path)\ntest_rgb_images = [os.path.join(test_rgb_path, x) for x in test_rgb_images]","metadata":{"id":"42e6ae95","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#empty value\ntest_label_path = os.path.join(workspace_path, 'test/label')\ntry:\n    test_label_images = os.listdir(test_label_path)\nexcept:\n    test_label_images = []\ntest_label_images = [os.path.join(test_label_path, x) for x in test_label_images]","metadata":{"id":"dbeb921a","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_dataset = CloudDataset(test_rgb_images, test_label_images,\n                            transforms=val_transforms, is_train=False)\ntest_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False,\n                                               num_workers=num_workers, pin_memory=True, drop_last=True)","metadata":{"id":"1ba27f1e","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 테스트 결과 저장","metadata":{"id":"5a055ede"}},{"cell_type":"code","source":"model.eval()\n\nresult_path = os.path.join(output_path, 'results')\nos.makedirs(result_path, exist_ok=True)\n\nwith torch.no_grad():\n    pbar = tqdm(enumerate(test_dataloader), total=len(test_dataloader))\n    for i, (imgs, img_path) in pbar:\n        imgs = imgs.to(device)\n        if model_name == 'deeplabv3':\n            preds = model(imgs)['out']\n        elif model_name == 'hrnet_w18' or model_name == 'hrnet_w48':\n            preds = model(imgs)\n            h, w = preds.shape[2], preds.shape[3]\n        elif model_name == 'dilated_unet':\n            preds = model(imgs)\n        \n        pred_img = np.zeros((*list(preds.shape[2:]), 3), dtype=np.uint8)\n        _, idx = preds.squeeze(0).max(0)\n        pos = idx == 0\n        pred_img[pos.cpu().numpy()] = [0, 0, 0]\n        pos = idx == 1\n        pred_img[pos.cpu().numpy()] = [0, 0, 255]\n        pos = idx == 2\n        pred_img[pos.cpu().numpy()] = [0, 255, 0]\n        pos = idx == 3\n        pred_img[pos.cpu().numpy()] = [0, 255, 255]\n        \n        cv2.imwrite(os.path.join(result_path, os.path.basename(img_path[0])), pred_img)\n","metadata":{"id":"eadca7d5","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Run-Length Encoding","metadata":{"id":"18494383"}},{"cell_type":"code","source":"import pandas as pd","metadata":{"id":"1e8d274d","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def mask2rle(img):\n    '''\n    img: numpy array, 1 - mask, 0 - background\n    Returns run length as string formatted\n    '''\n    pixels= img.T.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)","metadata":{"id":"f4ebad00","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_label_file_list = os.listdir(result_path)\ntest_label_path_list = [os.path.join(result_path, x) for x in test_label_file_list]","metadata":{"id":"cd9e1cbb","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"rle_list = []\nfor file_path in test_label_path_list:\n    img = cv2.imread(file_path)\n    rle = mask2rle(img)\n    rle_list.append(rle)","metadata":{"id":"92c7170e","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"submission = pd.read_csv(os.path.join(workspace_path, 'sample_submission.csv'))","metadata":{"id":"9851d2ed","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"submission['Image_Label'] = test_label_file_list\nsubmission['EncodedPixels'] = rle_list","metadata":{"id":"b0873d66","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"submission.to_csv('sample_submission3_adam.csv', index=False)","metadata":{"id":"7c595d0d","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"저장된 파일 확인:\")\nprint(os.listdir('/kaggle/working'))\n\n# 파일 내용 확인\nprint(\"\\n파일 내용 확인:\")\nsubmission_check = pd.read_csv('/kaggle/working/sample_submission4_adamW.csv')\nprint(submission_check.head())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import shutil\nshutil.make_archive('label', 'zip', result_path)","metadata":{"id":"0e74acfe","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"shutil.rmtree(os.path.join(output_path, 'cache'))\nshutil.rmtree(result_path)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"","metadata":{}}]}